{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: NLTK Tweeter Data\n",
    "\n",
    "Adapted from NLP lecture by Younes Bensouda Mourri. 2020. Natural Language Processing with Classification and Vector Spaces. DeepLearning.AI\n",
    "\n",
    "Run code cells to learn about NLTK and Tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# To downloads sample twitter dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mtwitter_samples\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# To downloads sample twitter dataset\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries at the beginning of your code\n",
    "import nltk \n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples    # Import sample Twitter dataset from NLTK 20K tweets\n",
    "\n",
    "import matplotlib.pyplot as plt            # Import visualization library\n",
    "import random                              # pseudo-random number generator\n",
    "\n",
    "import re                                  # regular expression library\n",
    "import string                              # string operations\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1. Twitter Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See an example of tweet from twitter_sample corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contributors': None, 'coordinates': None, 'text': \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\", 'user': {'screen_name': 'EveHollyHousley', 'time_zone': 'London', 'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/776873880/f89d8aa869414e41eefd804284a3d95c.jpeg', 'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/776873880/f89d8aa869414e41eefd804284a3d95c.jpeg', 'default_profile_image': False, 'url': None, 'profile_text_color': '333333', 'following': False, 'listed_count': 0, 'entities': {'description': {'urls': []}}, 'utc_offset': 3600, 'profile_sidebar_border_color': 'FFFFFF', 'name': 'Eve', 'favourites_count': 4759, 'followers_count': 450, 'location': 'Manchester', 'protected': False, 'notifications': False, 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/620302844093181952/M7IP4ZHa_normal.jpg', 'profile_use_background_image': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/620302844093181952/M7IP4ZHa_normal.jpg', 'lang': 'en', 'statuses_count': 4384, 'friends_count': 541, 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/383849833/1435267039', 'geo_enabled': True, 'is_translator': False, 'contributors_enabled': False, 'profile_sidebar_fill_color': 'DDEEF6', 'created_at': 'Sun Oct 02 16:42:30 +0000 2011', 'verified': False, 'profile_link_color': '0084B4', 'is_translation_enabled': False, 'has_extended_profile': False, 'id_str': '383849833', 'follow_request_sent': False, 'profile_background_color': 'C0DEED', 'default_profile': False, 'profile_background_tile': True, 'id': 383849833, 'description': 'Lauv it • 18 • Music Student'}, 'retweet_count': 0, 'favorited': False, 'entities': {'hashtags': [], 'user_mentions': [], 'urls': [], 'symbols': []}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'truncated': False, 'geo': None, 'in_reply_to_status_id_str': None, 'is_quote_status': False, 'in_reply_to_user_id_str': None, 'place': None, 'in_reply_to_status_id': None, 'in_reply_to_screen_name': None, 'lang': 'en', 'retweeted': False, 'in_reply_to_user_id': None, 'created_at': 'Fri Jul 24 10:42:48 +0000 2015', 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'}, 'favorite_count': 0, 'id_str': '624530162890219521', 'id': 624530162890219521}\n"
     ]
    }
   ],
   "source": [
    "print(twitter_samples.docs()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you are curious to see the content of twitter sample\n",
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load positive and negative tweets using  `strings()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select positive and negative tweets\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of positive and negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets:  5000\n",
      "Number of negative tweets:  5000\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive tweets: ', len(positive_tweets))\n",
    "print('Number of negative tweets: ', len(negative_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tweets are stored in a list and each individual tweet is stored as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tweets are stored as:  <class 'list'>\n",
      "Individual tweet is stored as:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('All tweets are stored as: ', type(positive_tweets))\n",
    "print('Individual tweet is stored as: ', type(negative_tweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize negataive and positive tweets distribution using Pie chart: (https://matplotlib.org/3.2.1/gallery/pie_and_polar_charts/pie_features.html#sphx-glr-gallery-pie-and-polar-charts-pie-features-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Declare Figure with a custom size\n",
    "fig1 = plt.figure(figsize=(5, 5))\n",
    "\n",
    "labels = 'Positives\\nTweets', 'Negative\\nTweets' # labels for the two classes\n",
    "\n",
    "sizes = [len(positive_tweets), len(negative_tweets)] # Sizes for each slide\n",
    "\n",
    "ax1 = plt.gca() # To get the current polar axes on the current figure\n",
    "\n",
    "# Declare pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', # formatting percent values\n",
    "        shadow=False, startangle=90)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.axis('equal')  \n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a random positive and a random negative tweet. Note tweets come from a public dataset and some tweets might have more explicit content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m@babagby thanks. I appreciate :)\n",
      "\u001b[91m@NikiNoox Not great right now. I'm feeling wobbly and just want to go home but I can't :(\n"
     ]
    }
   ],
   "source": [
    "# print positive tweets in greeen\n",
    "print('\\033[92m' + positive_tweets[random.randint(0,5000)])\n",
    "\n",
    "# print negative tweets in red\n",
    "print('\\033[91m' + negative_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2. Cleaning raw text\n",
    "\n",
    "* Remove hyperlink\n",
    "* Remove hashtags (#)\n",
    "* Remove retweet maarks (RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dum Dum Andar - Ram Sampath, Sona Mohapatra &amp; Samantha Edwards Mein Tulane to razi razi, Wah! That's Josh :) http://t.co/ul8MARDfhm\n"
     ]
    }
   ],
   "source": [
    "# Example with one tweet - feel free to select a different tweet. This tweet is selected sa an example with url and emojis\n",
    "tweet = positive_tweets[150]  \n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mDum Dum Andar - Ram Sampath, Sona Mohapatra &amp; Samantha Edwards Mein Tulane to razi razi, Wah! That's Josh :) http://t.co/ul8MARDfhm\n",
      "\u001b[94mDum Dum Andar - Ram Sampath, Sona Mohapatra &amp; Samantha Edwards Mein Tulane to razi razi, Wah! That's Josh :) \n"
     ]
    }
   ],
   "source": [
    "print('\\033[92m' + tweet) # original tweet\n",
    "\n",
    "# remove retweet \"RT\" and replace by empty space ''. Carot (^) indicating the beginning of the string.\n",
    "tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "# remove hyperlinks \n",
    "tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet2)\n",
    "\n",
    "# remove hashtags but keep the word\n",
    "tweet2 = re.sub(r'#', '', tweet2)\n",
    "\n",
    "# clean emojis if needed\n",
    "# Adapted from https://stackoverflow.com/a/49146722/330558\n",
    "emoji_pattern = re.compile(\n",
    "    u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
    "    u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
    "    u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
    "    u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
    "    u\"(\\ud83c[\\udde0-\\uddff])\"  # flags (iOS)\n",
    "    \"+\", flags=re.UNICODE)\n",
    "\n",
    "tweet2 = emoji_pattern.sub(r'', tweet2)\n",
    "print('\\033[94m' + tweet2) # cleaned tweet\n",
    "\n",
    "\n",
    "#https://towardsdatascience.com/text-preprocessing-for-data-scientist-3d2419c8199d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Tweeter Tokenizer:</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mDum Dum Andar - Ram Sampath, Sona Mohapatra &amp; Samantha Edwards Mein Tulane to razi razi, Wah! That's Josh :) \n",
      "\u001b[94m\n",
      "\n",
      "Tokenized string:\n",
      "['dum', 'dum', 'andar', '-', 'ram', 'sampath', ',', 'sona', 'mohapatra', '&', 'samantha', 'edwards', 'mein', 'tulane', 'to', 'razi', 'razi', ',', 'wah', '!', \"that's\", 'josh', ':)']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m' + tweet2)\n",
    "print('\\033[94m')\n",
    "\n",
    "# instantiate tokenizer class\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "\n",
    "# tokenize tweets\n",
    "tweet_tokens = tokenizer.tokenize(tweet2)\n",
    "\n",
    "print()\n",
    "print('Tokenized string:')\n",
    "print(tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Corrections\n",
    "\n",
    "For more information check https://textblob.readthedocs.io/en/dev/quickstart.html#spelling-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "misspled = 'I havv goood speling!'\n",
    "spel = TextBlob(misspled)\n",
    "print(spel.correct())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words and punctuations\n",
    "\n",
    "The next step is to remove stop words and punctuation. Stop words are words that don't add significant meaning to the text. You'll see the list provided by NLTK when you run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words\n",
      "\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "Punctuation\n",
      "\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Import the english stop words list from NLTK\n",
    "stopwords_english = stopwords.words('english') \n",
    "\n",
    "print('Stop words\\n')\n",
    "print(stopwords_english)\n",
    "\n",
    "print('\\nPunctuation\\n')\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reaad more about Emoticons and Emojis: https://towardsdatascience.com/text-preprocessing-for-data-scientist-3d2419c8199d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words list contains some words that could be important in some contexts. You might need to customize the stop words list for some applications. \n",
    "\n",
    "For the punctuation, certain tokens like ':)' and '...'  could be important in some applications as they are used to express emotions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m\n",
      "['dum', 'dum', 'andar', '-', 'ram', 'sampath', ',', 'sona', 'mohapatra', '&', 'samantha', 'edwards', 'mein', 'tulane', 'to', 'razi', 'razi', ',', 'wah', '!', \"that's\", 'josh', ':)']\n",
      "\u001b[94m\n",
      "removed stop words and punctuation:\n",
      "['dum', 'dum', 'andar', 'ram', 'sampath', 'sona', 'mohapatra', 'samantha', 'edwards', 'mein', 'tulane', 'razi', 'razi', 'wah', \"that's\", 'josh', ':)']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m')\n",
    "print(tweet_tokens)\n",
    "print('\\033[94m')\n",
    "\n",
    "tweets_clean = []\n",
    "\n",
    "for word in tweet_tokens: # Go through every word in your tokens list\n",
    "    if (word not in stopwords_english and  # remove stopwords\n",
    "        word not in string.punctuation):  # remove punctuation\n",
    "        tweets_clean.append(word)\n",
    "\n",
    "print('removed stop words and punctuation:')\n",
    "print(tweets_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m\n",
      "['dum', 'dum', 'andar', 'ram', 'sampath', 'sona', 'mohapatra', 'samantha', 'edwards', 'mein', 'tulane', 'razi', 'razi', 'wah', \"that's\", 'josh', ':)']\n",
      "\u001b[94m\n",
      "stemmed words:\n",
      "['dum', 'dum', 'andar', 'ram', 'sampath', 'sona', 'mohapatra', 'samantha', 'edward', 'mein', 'tulan', 'razi', 'razi', 'wah', \"that'\", 'josh', ':)']\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('\\033[92m')\n",
    "print(tweets_clean)\n",
    "print('\\033[94m')\n",
    "\n",
    "# Instantiate stemming class\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "# Create an empty list to store the stems\n",
    "tweets_stem = [] \n",
    "\n",
    "for word in tweets_clean:\n",
    "    stem_word = stemmer.stem(word)  # stemming word\n",
    "    tweets_stem.append(stem_word)  # append to the list\n",
    "\n",
    "print('stemmed words:')\n",
    "print(tweets_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process_tweet()\n",
    "\n",
    "Create your own function that will incorporate all pre-proccessing cleaning steps. Feel free to work/discuss in your study groups.\n",
    "\n",
    "In the future, you could just call that function when dealing with tweets.\n",
    "\n",
    "Alternatively check out the function from Analytics Vidhya (2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  \n",
    "                word not in string.punctuation): \n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: string.punctuation is a pre-initialized string used as string constant and it will give you a set of punctuation symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import string library function \n",
    "import string # actually we already imported string at the top\n",
    "    \n",
    "# Storing the sets of punctuation in variable result \n",
    "result = string.punctuation \n",
    "    \n",
    "# Printing the punctuation values \n",
    "print(result) # import string library function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3. Feature Extraction\n",
    "\n",
    "Using process_tweet function and Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = [process_tweet(tweet) for tweet in positive_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'jame', 'odd', ':/', 'pleas', 'call', 'contact', 'centr', '02392441234', 'abl', 'assist', ':)', 'mani', 'thank']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer has a parameter analyzer which is by default 'word'. Here we can replace it by our own customized tokenizer - process_tweet\n",
    "\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6623\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer=process_tweet).fit(positive_tweets)\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(count_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform all tweets and extract BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (5000, 6623)\n",
      "Amount of Non-Zero occurences:  32632\n"
     ]
    }
   ],
   "source": [
    "tweet_bow = count_vectorizer.transform(positive_tweets)\n",
    "print('Shape of Sparse Matrix: ', tweet_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', tweet_bow.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some exploration of Count Vectorizer samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(-:', '(:', '):', ');', '--->', '-->', '->', '.\\n.\\n.', '. .', '. . .']\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 58)\t1\n",
      "  (0, 63)\t1\n",
      "  (0, 274)\t1\n",
      "  (0, 401)\t1\n",
      "  (0, 1933)\t1\n",
      "  (0, 2329)\t1\n",
      "  (0, 2362)\t1\n",
      "  (0, 2471)\t1\n",
      "  (0, 3138)\t1\n",
      "  (0, 3973)\t1\n",
      "  (0, 4176)\t1\n",
      "  (0, 5022)\t1\n",
      "  (0, 5823)\t1\n",
      "(1, 6623)\n",
      "Great new opportunity for junior triathletes aged 12 and 13 at the Gatorade series! Get your entries in :) http://t.co/of3DyOzML0\n"
     ]
    }
   ],
   "source": [
    "bow14 = count_vectorizer.transform([positive_tweets[14]])\n",
    "print(bow14)\n",
    "print(bow14.shape)\n",
    "print(positive_tweets[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious to see the sparce matrix with transform tokens, select a small sample and fit_transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   02392441234  15  :)  :/  abl  accnt  amaz  assist  bleed  blue  call  centr  commun  congrat  contact  day  engag  fb  followfriday  got  hey  jame  last  listen  mani  mark  member  night  odd  pleas  profil  rqst  scotland  succeed  thank  tick  top  track  verifi  week  yeaaah  yipppi\n",
      "0            0   0   1   0    0      0     0       0      0     0     0      0       1        0        0    0      1   0             1    0    0     0     0       0     0     0       1      0    0      0       0     0         0        0      0     0    1      0       0     1       0       0\n",
      "1            1   0   1   1    1      0     0       1      0     0     1      1       0        0        1    0      0   0             0    0    1     1     0       0     1     0       0      0    1      1       0     0         0        0      1     0    0      0       0     0       0       0\n",
      "2            0   0   1   0    0      0     1       0      1     0     0      0       0        0        0    0      0   0             0    0    0     0     1       1     0     0       0      1    0      0       0     0         1        0      0     0    0      1       0     0       0       0\n",
      "3            0   0   1   0    0      0     0       0      0     0     0      0       0        1        0    0      0   0             0    0    0     0     0       0     0     0       0      0    0      0       0     0         0        0      0     0    0      0       0     0       0       0\n",
      "4            0   1   1   0    0      1     0       0      0     1     0      0       0        0        0    1      0   1             0    1    0     0     0       0     0     1       0      0    0      0       1     1         0        1      0     1    0      0       1     0       1       1\n",
      "--------------------------------------------------\n",
      "@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!\n"
     ]
    }
   ],
   "source": [
    "sample = positive_tweets[:5]\n",
    "Z = count_vectorizer.fit_transform(sample)\n",
    "# Original concept https://gist.github.com/larsmans/3745866\n",
    "print(pd.DataFrame(Z.A, columns=count_vectorizer.get_feature_names()).to_string())\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "print(sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most frequent words in positive tweets from BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_words = tweet_bow.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq = [(word, sum_words[0, idx]) for word, idx in count_vectorizer.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('commun', 289), ('centr', 128), ('rqst', 75), ('thank', 16), ('week', 8), (':)', 7), ('profil', 4), ('call', 3), ('congrat', 3), ('hey', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(words_freq[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "- https://medium.com/swlh/natural-language-processing-in-python-with-code-part-ii-18c8742762a4\n",
    "- https://medium.com/@meetnandu996/natural-language-processing-in-python-with-code-part-i-7736e3b112ab\n",
    "- https://medium.com/analytics-vidhya/natural-language-processing-ed71ff6e41f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
