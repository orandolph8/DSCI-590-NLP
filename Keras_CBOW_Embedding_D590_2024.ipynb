{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhoAVNSXL3gA"
      },
      "source": [
        "# Python Keras Handout - CBOW Model\n",
        "\n",
        "D-590 Fall 2024\n",
        "\n",
        "NLP\n",
        "\n",
        "Olga Scrivner & Siddharth Gosawi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXfvN1qIUluI"
      },
      "source": [
        "**CBOW model** predicts the _current word_ given context words within _specific window_.\n",
        "\n",
        "     - The input layer contains the context words\n",
        "     - The hidden layer contains the number of dimensions in which\n",
        "        we want to represent the current word presented at the output layer\n",
        "     - The output layer contains the current word\n",
        "\n",
        "\n",
        "![Mikolov et al., 2013](https://static.packt-cdn.com/products/9781786465825/graphics/B05525_03_05.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-FqRZUzwRRb"
      },
      "source": [
        "There are actually three frameworks to build CBOW model:\n",
        "\n",
        "### **tensorflow**\n",
        "- developed by Google researchers\n",
        "- designed to be used with python or javascript\n",
        "- python version can be installed via PYPI (pip)\n",
        "    - see documentation (license, release) - https://pypi.org/project/tensorflow/\n",
        "\n",
        "### **keras**\n",
        "\n",
        "- a neural network library (using tensoflow and theanos functionalities)\n",
        "- developed by a Google engineer François Chollet\n",
        "- designed to make implementing deep learning models as fast and easy as possible for research and development\n",
        "- requires tensoflow or theanos installation\n",
        "    - keras library can be installed via PYPI (pip)\n",
        "- see documentation (license, release) - https://pypi.org/project/keras/\n",
        "\n",
        "### **pytorch**\n",
        "\n",
        "- developed by facebook\n",
        "- allows for dynamic models deep learning\n",
        "        -  tensorflow/keras build static models\n",
        "        -  models have to be built from the beginning and then re-used\n",
        "    - can be installed via PYPI (pip)\n",
        "- see documentation - https://pypi.org/project/torch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1odhy-igMBRs"
      },
      "source": [
        "To build CBOW model we will be using a Python interface to Keras with tensorflow serving as a \"backend engine\".\n",
        "- Keras is a Python library for developing and evaluating deep learning models\n",
        "- TensorFlow is an open-source symbolic tensor manipulation framework developed by Google: [link](http://www.tensorflow.org/)\n",
        "- Keras uses the TensorFlow backend by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GIwHSoj4L2UZ"
      },
      "outputs": [],
      "source": [
        "# import keras.backend as K # K for Keras, just a common abbreviation\n",
        "import tensorflow.keras.backend as K # K for Keras, just a common abbreviation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq8f9zjpNVrs"
      },
      "source": [
        "**Sequential model** is used when you have One Input and One output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tyRM79gqNWPH"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiHO6tfbNxpp"
      },
      "source": [
        "\n",
        "Keras provides pre-built layers for different neural network architecture.\n",
        "- **Dense**\n",
        "    - _Dense Layer_ is used for creating a deeply connected layer where each of the neurons of the dense layers receives input from all neurons of the previous layer.\n",
        "- **Embedding**\n",
        "   - _Embedding layer_ is a compression of the output and is used to embed higher dimensional data into lower dimensional vector space\n",
        "- **Lambda**\n",
        "   - _Lambda Layer_ is used for _transforming_ input using an expression or function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lvP4tM27Nx_b"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Embedding, Lambda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6t-5tHbPlax"
      },
      "source": [
        "1. First you create a sequential constructor (similar to CountVectorizer() etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GvWCbddwPln7"
      },
      "outputs": [],
      "source": [
        "cbow = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3taTtw3sqIN"
      },
      "source": [
        "2. Then you can add layers to Sequential Contstructor using .add() and compile model with .compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9cLks8cQA67"
      },
      "source": [
        "## LAYER 1: Embedding Layer\n",
        "\n",
        "The Embedding layer generate weights. The output is a 2D vector with one embedding for each word .\n",
        "\n",
        "Embedding layer requires several arguments:\n",
        "\n",
        "- **input_dim**: We need to know $\\color{red}{vocabulary \\: size}$. `input_dim` should equal size of vocabulary + 1\n",
        "- **output_dim**: We need to select a $\\color{red}{dimension \\: size}$ for the dense embedding. This is the size of the vector space into which words will be embedded.\n",
        "       - when the layer is smaller , you compress more and lose more data.\n",
        "       - When the layer is bigger, you compress less and potentially overfit your input dataset to this layer.\n",
        "       - The larger vocabulary you have you want better representation of it - make the layer larger.\n",
        "       - If you have very sparse documents relatively to the vocabulary, then you want to \"get rid\" of unnecessary and\n",
        "          noisy words - you should compress more - make the embedding smaller.\n",
        "\n",
        "- **input_length**: Length of input sequences, when it is constant. In CBOW model, we use $\\color{red}{size \\: of \\: window*2}$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PChF-ylfuZ0"
      },
      "source": [
        "To generate `input_dim`, we need to build a vocabulary maping:\n",
        "- extract each unique word from corpus vocabulary and map a unique numeric identifier to it.\n",
        "\n",
        "Keras provides a utility for text preprocesssing `from keras.preprocessing import text` ([see description of all functionalities](https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/text.py)).\n",
        "- `Tokenizer()` is a class with several methods:\n",
        "    - `fit_on_texts`  - updates internal vocabulary based on a list of texts\n",
        "    - `word_index` - create a dictionary with words and their indices:\n",
        "           dict(zip(sorted_voc, list(range(1, len(sorted_voc) + 1)))) # from documentation (see link above)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClyNHj-r6bic"
      },
      "source": [
        "We are going tto create a small corpus for illustration purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtWG-Gxl582Z",
        "outputId": "ebbd0c94-2a31-426f-c51d-34c401aebcf0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9fArQ9TLsnZX"
      },
      "outputs": [],
      "source": [
        "# Using a small example\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "corpus = ['The sky is blue and beautiful.',\n",
        "          'Love this blue and beautiful sky!',\n",
        "          'The quick brown fox jumps over the lazy dog.',\n",
        "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "          'I love green eggs, ham, sausages and bacon!',\n",
        "          'The brown fox is quick and the blue dog is lazy!',\n",
        "          'The sky is very blue and the sky is very beautiful today',\n",
        "          'The dog is lazy but the brown fox is quick!'\n",
        "]\n",
        "corpus = np.array(corpus)\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = wpt.tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "normalize_corpus = np.vectorize(normalize_document)\n",
        "norm_corpus = normalize_corpus(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_9ro00s8G0m",
        "outputId": "ea56ba6f-e622-466f-e388-3be7e2adb3aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['sky blue beautiful', 'love blue beautiful sky',\n",
              "       'quick brown fox jumps lazy dog',\n",
              "       'kings breakfast sausages ham bacon eggs toast beans',\n",
              "       'love green eggs ham sausages bacon',\n",
              "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
              "       'dog lazy brown fox quick'], dtype='<U51')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "norm_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuwG6mcosoiI"
      },
      "source": [
        "We will now import necessary keras library to generate vocabulary mapping for CBOW."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KOQzbQTfrdbB"
      },
      "outputs": [],
      "source": [
        "# from keras.preprocessing import text\n",
        "from tensorflow.keras.preprocessing import text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MiuTdJhq7EQB"
      },
      "outputs": [],
      "source": [
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(norm_corpus)\n",
        "word2id = tokenizer.word_index\n",
        "word2id['PAD'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS1K2nqq7exJ"
      },
      "source": [
        "Note: word2id creates a map of word and its index (unique identifier). Index always start with 1. \"sky\" is the first token after preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uNpPhIQ7aok",
        "outputId": "b85a7935-937d-4951-c5f5-61aa9677b03a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sky': 1,\n",
              " 'blue': 2,\n",
              " 'beautiful': 3,\n",
              " 'quick': 4,\n",
              " 'brown': 5,\n",
              " 'fox': 6,\n",
              " 'lazy': 7,\n",
              " 'dog': 8,\n",
              " 'love': 9,\n",
              " 'sausages': 10,\n",
              " 'ham': 11,\n",
              " 'bacon': 12,\n",
              " 'eggs': 13,\n",
              " 'jumps': 14,\n",
              " 'kings': 15,\n",
              " 'breakfast': 16,\n",
              " 'toast': 17,\n",
              " 'beans': 18,\n",
              " 'green': 19,\n",
              " 'today': 20,\n",
              " 'PAD': 0}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r95gfElbHYzo"
      },
      "source": [
        "We also need to create a reverse mapping from Index to Word `id2word` and word mapping to their sentences `wids`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7mWOSk5HKTT",
        "outputId": "5b795bbe-4e90-4a66-a48d-d636b678ed4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size 21\n",
            "Index to Word\n",
            "{1: 'sky', 2: 'blue', 3: 'beautiful', 4: 'quick', 5: 'brown', 6: 'fox', 7: 'lazy', 8: 'dog', 9: 'love', 10: 'sausages', 11: 'ham', 12: 'bacon', 13: 'eggs', 14: 'jumps', 15: 'kings', 16: 'breakfast', 17: 'toast', 18: 'beans', 19: 'green', 20: 'today', 0: 'PAD'}\n",
            "Index to Sentence\n",
            "[[1, 2, 3], [9, 2, 3, 1], [4, 5, 6, 14, 7, 8], [15, 16, 10, 11, 12, 13, 17, 18], [9, 19, 13, 11, 10, 12], [5, 6, 4, 2, 8, 7], [1, 2, 1, 3, 20], [8, 7, 5, 6, 4]]\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(word2id)\n",
        "id2word = {v:k for k, v in word2id.items()}\n",
        "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_corpus]\n",
        "print(\"Vocabulary size\", vocab_size)\n",
        "print(\"Index to Word\")\n",
        "print(id2word)\n",
        "print(\"Index to Sentence\")\n",
        "print(wids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbuVMwhU8dYD"
      },
      "source": [
        "Padding is typically used to pad context words to a fixed length if needed. Most neural networks require the input sequence data with **the same length** so we need **padding**: to truncate or pad sequence (pad with 0s) into the same length.\n",
        "\n",
        "        - Notice that Index starts always with \"1\" because \"0\" is reserved for padding.\n",
        " Figure  below shows how zeros are added to shorter sequences to keep the same length for all sequences (sentences) and the first sequences is truncated aat the beginning.     \n",
        "\n",
        "![](https://miro.medium.com/max/1750/1*CPLhZoVSTCWgAxe2LKXoOA.png)\n",
        "source: https://towardsdatascience.com/hands-on-nlp-deep-learning-model-preparation-in-tensorflow-2-x-2e8c9f3c7633\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMXVqUNI81Be"
      },
      "source": [
        "`pad_sequence()` function from keras.preprocessing.sequence allows to add padding at the beggining (padding='pre') or at the end of the sequence (padding = 'post'). If the maximum length (`maxlen`) is not defined, it will take the size of the longuest sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y2CfZw6AHwxz"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qaH3leO4xo3",
        "outputId": "cc7d4010-9d24-431b-afc8-39c000ba9cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  1  2  3]\n",
            " [ 0  0  0  0  9  2  3  1]\n",
            " [ 0  0  4  5  6 14  7  8]\n",
            " [15 16 10 11 12 13 17 18]\n",
            " [ 0  0  9 19 13 11 10 12]\n",
            " [ 0  0  5  6  4  2  8  7]\n",
            " [ 0  0  0  1  2  1  3 20]\n",
            " [ 0  0  0  8  7  5  6  4]]\n"
          ]
        }
      ],
      "source": [
        "# max_length = 4 # you can try changing maximum length for padding\n",
        "padded_docs = pad_sequences(wids,  padding='pre') # maxlen=max_length,\n",
        "print(padded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Go_9i8sc2D"
      },
      "source": [
        "Finally we need to import keras utility helper function `from keras.utils import np_utils` (numpy related utility [link]{https://www.kite.com/python/docs/keras.utils.np_utils})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6kvuYAI4siwV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDRnkHwM64E5"
      },
      "source": [
        "- We will be choosing our context window size = 2. Window size depends how many words on the left and right we want to include.\n",
        "- We will choose embedding size = 100. Our matrix will be vocabulary size x embeddeding size. This will be ouur output dimension (read ta the top about how to choose embedding size = `output_dim`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xgRdNeqgNYWz"
      },
      "outputs": [],
      "source": [
        "embed_size = 100\n",
        "window_size = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99Q-XWHFpWJD"
      },
      "source": [
        "The embedding layer is added to Sequential() Constructor with the following parameters:\n",
        "- input dimension = vocabulary size (20),\n",
        "- output ddimension = embedding size (100), a hyper-parameter\n",
        "- input length = window context (2*2 = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yn0O0w-nQBKn"
      },
      "outputs": [],
      "source": [
        "# cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
        "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkiuqTvRxEic"
      },
      "source": [
        "- **Input Shape** = 4 x 100 (4,100).\n",
        "- **Output shape** = (None, 4, 100), where the first value represent **batch** size.\n",
        "    - `None` means the size/dimension is variable but each sample in the batch will always have a shape 4x100. So output is (None, 4,100)\n",
        "    - If `batch size` is defined, then it is the subset size of your training sample (e.g. 100 out of 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11qlyxPaqh81"
      },
      "source": [
        "## LAYER 2: Lambda Layer\n",
        "\n",
        "Lambda is a wrapper for your function. For example, if you wanted to build a layer that squares its input, you could state:\n",
        "\n",
        "`model.add(lambda(lambda x: x ** 2))`\n",
        "\n",
        "In our case, Lambda layer will return the average of weights `mean`. Axis value specifies the axis along which the means are computed: **1** = along the column. The output dimention will be 100 (1-dimension).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4kkKWhhH1SbS"
      },
      "outputs": [],
      "source": [
        "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmGDqmysDXT9"
      },
      "source": [
        "## LAYER 3: Dense Layer\n",
        "\n",
        "Dense layer is a neural network layer that is fully connected:  each neuron in the dense layer receives input from all neurons of its previous layer\n",
        "\n",
        "- **unit** is the output size (just a positive integer)\n",
        "    - we use vocab size = 20 as output size\n",
        "- **activation** represents the activation function (e.g. softmax, sigmoid, ReLU)\n",
        "    - we use `softmax` which converts a vector of values to a probability distribution: output vector values are in range (0, 1) and sum to 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DwPTfehV_6Wv"
      },
      "outputs": [],
      "source": [
        "cbow.add(Dense(vocab_size, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drlz8yLMIiCN"
      },
      "source": [
        "### Compile Method\n",
        "\n",
        "Compile method configures the learning process. For the list of available optimizers [see link](https://faroit.com/keras-docs/1.1.0/optimizers/)\n",
        "\n",
        "- **RMSprop Optimizer**: RMSprop is a gradient-based optimization technique used in training neural networks. This normalization balances the step size (momentum), decreasing the step for large gradients to avoid exploding and increasing the step for small gradients to avoid vanishing [see link](https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be)\n",
        "\n",
        "- **Categorical Crossentropy** is used to compute the crossentropy loss between the labels and predictions.\n",
        "   - Crossentropy is a measure of the difference between two probability distributions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "N8c97Juj_9oC"
      },
      "outputs": [],
      "source": [
        "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "cbow.build(input_shape=(None, window_size*2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hO8I61otbHs"
      },
      "source": [
        "Using `model.summary()` we can see an overview of the model architecture.\n",
        "\n",
        "Each layer has an output and its shape is shown in the “Output Shape” column. Each layer’s output becomes the input for the subsequent layer.\n",
        "\n",
        "The “Param #” column shows you the number of parameters that are trained for each layer.\n",
        "\n",
        "Initial input is 1 x Vocabulary (a vector of size 21)\n",
        "\n",
        "- Embedding Layer\n",
        "  - The input layer will take a 2-D matrix of shape (None, 21) which means that each sample must be reshaped into a vector of 21 elements.\n",
        "  - The output layer will be 3-D matrix of shape (None, 4, 100)\n",
        "  - The number of parameters will be 21 x 100 = 2100\n",
        "- Lambda Layer (averaging weights)\n",
        "  - The input will take the output from Embedding layer (3-D matrix)\n",
        "  - The output is 2-D matrix (None, 100), each batch sample must be shaped into a vector of 100 elements. Since Lambda is simply wrapping the function, there is no parameters.\n",
        "- Dense Layer\n",
        "  - The input is 2-D matrix from Lambda layer\n",
        "  - The output is 2-D matrix (None, 21) with sample batches as a vector of 20 elements (vocabulary size)\n",
        "  - The number of parameters = 100x21 plus number of biases for each node = 2121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "9Cc-oYlDAAi9",
        "outputId": "6d0c3581-e519-47ef-a7cf-cd1e691dc148"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,121</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │           \u001b[38;5;34m2,100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │           \u001b[38;5;34m2,121\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,221</span> (16.49 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,221\u001b[0m (16.49 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,221</span> (16.49 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,221\u001b[0m (16.49 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(cbow.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nBjP8XCbfJr",
        "outputId": "176ce720-234b-4096-c216-32057ebd790c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedding (None, 4)\n",
            "lambda (None, 4, 100)\n",
            "dense (None, 100)\n"
          ]
        }
      ],
      "source": [
        "# for layer in cbow.layers:\n",
        "#   print(layer.name, input_shape)\n",
        "for layer in cbow.layers:\n",
        "    input_shape = K.int_shape(layer.input)\n",
        "    print(layer.name, input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9rYBcVmcNJK"
      },
      "source": [
        "## Generating Context pairs for CBOW Model\n",
        "\n",
        "Our function uses np_utils to convert vectors back to input matrix and sequence.pad_sequence to add zeros if the context length < 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IQ-7gUi81EUx"
      },
      "outputs": [],
      "source": [
        "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
        "    context_length = window_size*2\n",
        "    for words in corpus:\n",
        "        sentence_length = len(words)\n",
        "        #print(words)\n",
        "        for index, word in enumerate(words):\n",
        "            #print(index,word)\n",
        "            context_words = []\n",
        "            label_word   = []\n",
        "            start = index - window_size\n",
        "            end = index + window_size + 1\n",
        "\n",
        "            context_words.append([words[i]\n",
        "                                 for i in range(start, end)\n",
        "                                 if 0 <= i < sentence_length\n",
        "                                 and i != index])\n",
        "            label_word.append(word)\n",
        "            #print(word)\n",
        "            x = pad_sequences(context_words, maxlen=context_length)\n",
        "            y = np_utils.to_categorical(label_word, vocab_size)\n",
        "            yield (x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rfgTWJN1LV4",
        "outputId": "efaf87fc-bf89-4928-b547-a6d33292d7ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 0]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 0]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 0]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 1]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 1 2]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 2 3]] [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 1 3]] [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 1 2]] [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 0]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 0]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 9]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 9 2]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 2 3]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 9 3 1]] [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 9 2 1]] [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 2 3]] [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 4]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 4 5]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 5 6]] [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 0  4  6 14]] [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 4  5 14  7]] [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "6\n",
            "Context (X): ['quick', 'brown', 'jumps', 'lazy'] -> Target (Y): fox\n",
            "[[5 6 7 8]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "14\n",
            "Context (X): ['brown', 'fox', 'lazy', 'dog'] -> Target (Y): jumps\n",
            "[[ 0  6 14  8]] [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 0  0 14  7]] [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 0  0 16 10]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "[[ 0 15 10 11]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "[[15 16 11 12]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "10\n",
            "Context (X): ['kings', 'breakfast', 'ham', 'bacon'] -> Target (Y): sausages\n",
            "[[16 10 12 13]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "11\n",
            "Context (X): ['breakfast', 'sausages', 'bacon', 'eggs'] -> Target (Y): ham\n",
            "[[10 11 13 17]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "12\n",
            "Context (X): ['sausages', 'ham', 'eggs', 'toast'] -> Target (Y): bacon\n",
            "[[11 12 17 18]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "13\n",
            "Context (X): ['ham', 'bacon', 'toast', 'beans'] -> Target (Y): eggs\n",
            "[[ 0 12 13 18]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "[[ 0  0 13 17]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
            "[[0 0 0 9]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 0  0  9 19]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 0  0 19 13]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 0  9 13 11]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "[[ 9 19 11 10]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "13\n",
            "Context (X): ['love', 'green', 'ham', 'sausages'] -> Target (Y): eggs\n",
            "[[19 13 10 12]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "11\n",
            "Context (X): ['green', 'eggs', 'sausages', 'bacon'] -> Target (Y): ham\n",
            "[[ 0 13 11 12]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 0  0 11 10]] [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 5]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 5 6]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 6 4]] [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 5 4 2]] [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[5 6 2 8]] [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "4\n",
            "Context (X): ['brown', 'fox', 'blue', 'dog'] -> Target (Y): quick\n",
            "[[6 4 8 7]] [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "2\n",
            "Context (X): ['fox', 'quick', 'dog', 'lazy'] -> Target (Y): blue\n",
            "[[0 4 2 7]] [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 2 8]] [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 0]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 0 1]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 1 2]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 0 2 1]] [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0 1 1 3]] [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[ 1  2  3 20]] [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "1\n",
            "Context (X): ['sky', 'blue', 'beautiful', 'today'] -> Target (Y): sky\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for x, y in generate_context_word_pairs(corpus=padded_docs, window_size=window_size, vocab_size=vocab_size):\n",
        "    print(x,y)\n",
        "    if 0 not in x[0]:\n",
        "        print(np.argwhere(y[0])[0][0])\n",
        "        print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
        "        #print(id2word[np.argwhere(y[0])[0][0]])\n",
        "        if i == 10:\n",
        "            break\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "DGhlFtD0ccXu",
        "outputId": "79733a49-8d54-440e-e076-bfa3b53bc161"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"350pt\" height=\"300pt\" viewBox=\"0.00 0.00 388.00 332.00\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.9 0.9) rotate(0) translate(4 328)\">\n",
              "<title>G</title>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-328 384,-328 384,4 -4,4\"/>\n",
              "<!-- 137536751373904 -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>137536751373904</title>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"7.5,-240.5 7.5,-323.5 372.5,-323.5 372.5,-240.5 7.5,-240.5\"/>\n",
              "<polygon fill=\"black\" stroke=\"transparent\" points=\"7.5,-240.5 7.5,-323.5 372.5,-323.5 372.5,-240.5 7.5,-240.5\"/>\n",
              "<polygon fill=\"black\" stroke=\"transparent\" points=\"10,-281 10,-321 371,-321 371,-281 10,-281\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"10,-281 10,-321 371,-321 371,-281 10,-281\"/>\n",
              "<text text-anchor=\"start\" x=\"146.5\" y=\"-298.2\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"16.00\" fill=\"white\">Embedding</text>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"10,-242 10,-279 169,-279 169,-242 10,-242\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"10,-242 10,-279 169,-279 169,-242 10,-242\"/>\n",
              "<text text-anchor=\"start\" x=\"21\" y=\"-257.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Input shape: </text>\n",
              "<text text-anchor=\"start\" x=\"100\" y=\"-257.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">(None, 4)</text>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"171,-242 171,-279 371,-279 371,-242 171,-242\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"171,-242 171,-279 371,-279 371,-242 171,-242\"/>\n",
              "<text text-anchor=\"start\" x=\"182\" y=\"-257.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Output shape: </text>\n",
              "<text text-anchor=\"start\" x=\"272\" y=\"-257.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">(None, 4, 100)</text>\n",
              "</g>\n",
              "<!-- 137536749854512 -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>137536749854512</title>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"0,-120.5 0,-203.5 380,-203.5 380,-120.5 0,-120.5\"/>\n",
              "<polygon fill=\"black\" stroke=\"transparent\" points=\"0,-120.5 0,-203.5 380,-203.5 380,-120.5 0,-120.5\"/>\n",
              "<polygon fill=\"black\" stroke=\"transparent\" points=\"2,-161 2,-201 378,-201 378,-161 2,-161\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"2,-161 2,-201 378,-201 378,-161 2,-161\"/>\n",
              "<text text-anchor=\"start\" x=\"159\" y=\"-178.2\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"16.00\" fill=\"white\">Lambda</text>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"2,-122 2,-159 191,-159 191,-122 2,-122\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"2,-122 2,-159 191,-159 191,-122 2,-122\"/>\n",
              "<text text-anchor=\"start\" x=\"13\" y=\"-137.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Input shape: </text>\n",
              "<text text-anchor=\"start\" x=\"92\" y=\"-137.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">(None, 4, 100)</text>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"193,-122 193,-159 378,-159 378,-122 193,-122\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"193,-122 193,-159 378,-159 378,-122 193,-122\"/>\n",
              "<text text-anchor=\"start\" x=\"204\" y=\"-137.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Output shape: </text>\n",
              "<text text-anchor=\"start\" x=\"294\" y=\"-137.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">(None, 100)</text>\n",
              "</g>\n",
              "<!-- 137536751373904&#45;&gt;137536749854512 -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>137536751373904-&gt;137536749854512</title>\n",
              "<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M190,-240.37C190,-240.37 190,-213.56 190,-213.56\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"193.5,-213.56 190,-203.56 186.5,-213.56 193.5,-213.56\"/>\n",
              "</g>\n",
              "<!-- 137536749853264 -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>137536749853264</title>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"11,-0.5 11,-83.5 369,-83.5 369,-0.5 11,-0.5\"/>\n",
              "<polygon fill=\"black\" stroke=\"transparent\" points=\"11,-0.5 11,-83.5 369,-83.5 369,-0.5 11,-0.5\"/>\n",
              "<polygon fill=\"black\" stroke=\"transparent\" points=\"13,-41 13,-81 367,-81 367,-41 13,-41\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"13,-41 13,-81 367,-81 367,-41 13,-41\"/>\n",
              "<text text-anchor=\"start\" x=\"165.5\" y=\"-58.2\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"16.00\" fill=\"white\">Dense</text>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"13,-2 13,-39 187,-39 187,-2 13,-2\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"13,-2 13,-39 187,-39 187,-2 13,-2\"/>\n",
              "<text text-anchor=\"start\" x=\"24\" y=\"-17.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Input shape: </text>\n",
              "<text text-anchor=\"start\" x=\"103\" y=\"-17.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">(None, 100)</text>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"189,-2 189,-39 367,-39 367,-2 189,-2\"/>\n",
              "<polygon fill=\"none\" stroke=\"black\" points=\"189,-2 189,-39 367,-39 367,-2 189,-2\"/>\n",
              "<text text-anchor=\"start\" x=\"200\" y=\"-17.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Output shape: </text>\n",
              "<text text-anchor=\"start\" x=\"290\" y=\"-17.8\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">(None, 21)</text>\n",
              "</g>\n",
              "<!-- 137536749854512&#45;&gt;137536749853264 -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>137536749854512-&gt;137536749853264</title>\n",
              "<path fill=\"none\" stroke=\"black\" stroke-width=\"2\" d=\"M190,-120.37C190,-120.37 190,-93.56 190,-93.56\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"2\" points=\"193.5,-93.56 190,-83.56 186.5,-93.56 193.5,-93.56\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import model_to_dot\n",
        "\n",
        "#display(SVG(model_to_dot(cbow, show_shapes=True, show_layer_names=False,\n",
        "   #              rankdir='TB', dpi=65).create(prog='dot', format='svg'))) # use dpi to reduce size of the image\n",
        "\n",
        "SVG(model_to_dot(cbow, show_shapes=True, show_layer_names=False,\n",
        "rankdir='TB', dpi=65).create(prog='dot', format='svg'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OBV2KdGdFGS"
      },
      "source": [
        "### Training\n",
        "\n",
        "- **Epoch** is the number of passes over the data\n",
        "- **Loss** is the error over the training set\n",
        "- The lower loss value, the better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBPFOX-JdEiQ",
        "outputId": "0ca12224-a326-45f5-e2d1-899252c30e65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7d16c40bb520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7d16c40bb520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 10 (context, word) pairs\n",
            "Processed 20 (context, word) pairs\n",
            "Processed 30 (context, word) pairs\n",
            "Processed 40 (context, word) pairs\n",
            "Processed 50 (context, word) pairs\n",
            "Processed 60 (context, word) pairs\n",
            "Epoch: 1 \tLoss: 190.0151083469391\n",
            "\n",
            "Processed 10 (context, word) pairs\n",
            "Processed 20 (context, word) pairs\n",
            "Processed 30 (context, word) pairs\n",
            "Processed 40 (context, word) pairs\n",
            "Processed 50 (context, word) pairs\n",
            "Processed 60 (context, word) pairs\n",
            "Epoch: 2 \tLoss: 182.72244691848755\n",
            "\n",
            "Processed 10 (context, word) pairs\n",
            "Processed 20 (context, word) pairs\n",
            "Processed 30 (context, word) pairs\n",
            "Processed 40 (context, word) pairs\n",
            "Processed 50 (context, word) pairs\n",
            "Processed 60 (context, word) pairs\n",
            "Epoch: 3 \tLoss: 174.18082356452942\n",
            "\n",
            "Processed 10 (context, word) pairs\n",
            "Processed 20 (context, word) pairs\n",
            "Processed 30 (context, word) pairs\n",
            "Processed 40 (context, word) pairs\n",
            "Processed 50 (context, word) pairs\n",
            "Processed 60 (context, word) pairs\n",
            "Epoch: 4 \tLoss: 166.622713804245\n",
            "\n",
            "Processed 10 (context, word) pairs\n",
            "Processed 20 (context, word) pairs\n",
            "Processed 30 (context, word) pairs\n",
            "Processed 40 (context, word) pairs\n",
            "Processed 50 (context, word) pairs\n",
            "Processed 60 (context, word) pairs\n",
            "Epoch: 5 \tLoss: 161.0120530128479\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 6):\n",
        "    loss = 0.\n",
        "    i = 0\n",
        "    for x, y in generate_context_word_pairs(corpus=padded_docs, window_size=window_size, vocab_size=vocab_size):\n",
        "        i += 1\n",
        "        loss += cbow.train_on_batch(x, y)\n",
        "        if i % 10 == 0:\n",
        "            print('Processed {} (context, word) pairs'.format(i))\n",
        "\n",
        "    print('Epoch:', epoch, '\\tLoss:', loss)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Cvhd8lgj_O"
      },
      "source": [
        "### Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "tn0jeanQhlFL",
        "outputId": "a5d52aa3-28c0-46fb-9a96-8ecb1dcf6a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix Shape:  (20, 100)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-caaecc26-dc9e-4b4c-a48e-24f64d8bf5f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>blue</th>\n",
              "      <td>-0.076501</td>\n",
              "      <td>0.029894</td>\n",
              "      <td>-0.011570</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>-0.029992</td>\n",
              "      <td>-0.096430</td>\n",
              "      <td>0.080132</td>\n",
              "      <td>0.062998</td>\n",
              "      <td>-0.041141</td>\n",
              "      <td>-0.054155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016111</td>\n",
              "      <td>-0.000824</td>\n",
              "      <td>-0.035780</td>\n",
              "      <td>0.023506</td>\n",
              "      <td>0.032977</td>\n",
              "      <td>-0.084966</td>\n",
              "      <td>0.098195</td>\n",
              "      <td>0.002915</td>\n",
              "      <td>-0.048796</td>\n",
              "      <td>0.014309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beautiful</th>\n",
              "      <td>0.002116</td>\n",
              "      <td>0.027616</td>\n",
              "      <td>-0.014997</td>\n",
              "      <td>0.033669</td>\n",
              "      <td>0.025789</td>\n",
              "      <td>0.006309</td>\n",
              "      <td>0.092553</td>\n",
              "      <td>-0.006395</td>\n",
              "      <td>-0.027339</td>\n",
              "      <td>0.028614</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017629</td>\n",
              "      <td>0.037911</td>\n",
              "      <td>-0.012956</td>\n",
              "      <td>0.019173</td>\n",
              "      <td>-0.043351</td>\n",
              "      <td>0.046808</td>\n",
              "      <td>0.029186</td>\n",
              "      <td>-0.023649</td>\n",
              "      <td>-0.023404</td>\n",
              "      <td>-0.086183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quick</th>\n",
              "      <td>-0.043192</td>\n",
              "      <td>0.051912</td>\n",
              "      <td>0.027199</td>\n",
              "      <td>0.019034</td>\n",
              "      <td>-0.070214</td>\n",
              "      <td>-0.108553</td>\n",
              "      <td>0.041518</td>\n",
              "      <td>-0.025373</td>\n",
              "      <td>0.114055</td>\n",
              "      <td>0.030910</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072342</td>\n",
              "      <td>0.095504</td>\n",
              "      <td>-0.034126</td>\n",
              "      <td>0.033947</td>\n",
              "      <td>0.015687</td>\n",
              "      <td>-0.048809</td>\n",
              "      <td>0.091568</td>\n",
              "      <td>0.001981</td>\n",
              "      <td>0.022970</td>\n",
              "      <td>-0.029967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brown</th>\n",
              "      <td>0.001223</td>\n",
              "      <td>0.012266</td>\n",
              "      <td>-0.039873</td>\n",
              "      <td>0.023260</td>\n",
              "      <td>-0.048432</td>\n",
              "      <td>0.024857</td>\n",
              "      <td>-0.067200</td>\n",
              "      <td>0.066255</td>\n",
              "      <td>-0.003667</td>\n",
              "      <td>-0.096556</td>\n",
              "      <td>...</td>\n",
              "      <td>0.096428</td>\n",
              "      <td>-0.008556</td>\n",
              "      <td>-0.123557</td>\n",
              "      <td>0.010775</td>\n",
              "      <td>0.045516</td>\n",
              "      <td>-0.041226</td>\n",
              "      <td>0.012991</td>\n",
              "      <td>0.019498</td>\n",
              "      <td>-0.033269</td>\n",
              "      <td>-0.061553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fox</th>\n",
              "      <td>0.024175</td>\n",
              "      <td>-0.011714</td>\n",
              "      <td>-0.082073</td>\n",
              "      <td>-0.023409</td>\n",
              "      <td>0.035770</td>\n",
              "      <td>0.050246</td>\n",
              "      <td>-0.026845</td>\n",
              "      <td>0.087967</td>\n",
              "      <td>-0.019296</td>\n",
              "      <td>-0.068626</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010911</td>\n",
              "      <td>0.057695</td>\n",
              "      <td>-0.117854</td>\n",
              "      <td>0.021435</td>\n",
              "      <td>-0.002695</td>\n",
              "      <td>0.068406</td>\n",
              "      <td>-0.063331</td>\n",
              "      <td>0.054215</td>\n",
              "      <td>-0.000422</td>\n",
              "      <td>-0.008547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caaecc26-dc9e-4b4c-a48e-24f64d8bf5f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-caaecc26-dc9e-4b4c-a48e-24f64d8bf5f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-caaecc26-dc9e-4b4c-a48e-24f64d8bf5f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4bf313c-aa98-4790-8a02-7e49f0d88b79\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4bf313c-aa98-4790-8a02-7e49f0d88b79')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4bf313c-aa98-4790-8a02-7e49f0d88b79 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 0         1         2         3         4         5   \\\n",
              "blue      -0.076501  0.029894 -0.011570  0.011102 -0.029992 -0.096430   \n",
              "beautiful  0.002116  0.027616 -0.014997  0.033669  0.025789  0.006309   \n",
              "quick     -0.043192  0.051912  0.027199  0.019034 -0.070214 -0.108553   \n",
              "brown      0.001223  0.012266 -0.039873  0.023260 -0.048432  0.024857   \n",
              "fox        0.024175 -0.011714 -0.082073 -0.023409  0.035770  0.050246   \n",
              "\n",
              "                 6         7         8         9   ...        90        91  \\\n",
              "blue       0.080132  0.062998 -0.041141 -0.054155  ...  0.016111 -0.000824   \n",
              "beautiful  0.092553 -0.006395 -0.027339  0.028614  ...  0.017629  0.037911   \n",
              "quick      0.041518 -0.025373  0.114055  0.030910  ... -0.072342  0.095504   \n",
              "brown     -0.067200  0.066255 -0.003667 -0.096556  ...  0.096428 -0.008556   \n",
              "fox       -0.026845  0.087967 -0.019296 -0.068626  ... -0.010911  0.057695   \n",
              "\n",
              "                 92        93        94        95        96        97  \\\n",
              "blue      -0.035780  0.023506  0.032977 -0.084966  0.098195  0.002915   \n",
              "beautiful -0.012956  0.019173 -0.043351  0.046808  0.029186 -0.023649   \n",
              "quick     -0.034126  0.033947  0.015687 -0.048809  0.091568  0.001981   \n",
              "brown     -0.123557  0.010775  0.045516 -0.041226  0.012991  0.019498   \n",
              "fox       -0.117854  0.021435 -0.002695  0.068406 -0.063331  0.054215   \n",
              "\n",
              "                 98        99  \n",
              "blue      -0.048796  0.014309  \n",
              "beautiful -0.023404 -0.086183  \n",
              "quick      0.022970 -0.029967  \n",
              "brown     -0.033269 -0.061553  \n",
              "fox       -0.000422 -0.008547  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "weights = cbow.get_weights()[0]\n",
        "weights = weights[1:]\n",
        "print(\"Matrix Shape: \", weights.shape)\n",
        "\n",
        "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGsc90Kgh-gU",
        "outputId": "aa75faac-5e7d-4ac4-8f09-8bc657d8a8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 20)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'quick': ['lazy', 'jumps', 'green', 'beans', 'today'],\n",
              " 'fox': ['dog', 'jumps', 'toast', 'beans', 'kings']}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "# compute pairwise distance matrix\n",
        "distance_matrix = euclidean_distances(weights)\n",
        "print(distance_matrix.shape)\n",
        "\n",
        "# view contextually similar words\n",
        "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:6]+1]\n",
        "                   for search_term in ['quick', 'fox']}\n",
        "\n",
        "similar_words"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (ADT)",
      "language": "python",
      "name": "adt"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
